{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Report of  Relation Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Kill       0.99      0.58      0.73       336\n",
      "     Live_In       0.85      0.65      0.73       476\n",
      "  Located_In       0.95      0.49      0.65       530\n",
      "        None       0.85      0.98      0.91      4904\n",
      " OrgBased_In       0.87      0.63      0.73       435\n",
      "    Work_For       0.88      0.65      0.75       382\n",
      "\n",
      "    accuracy                           0.86      7063\n",
      "   macro avg       0.90      0.66      0.75      7063\n",
      "weighted avg       0.87      0.86      0.85      7063\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Kill       0.50      0.50      0.50         2\n",
      "     Live_In       0.50      1.00      0.67         2\n",
      "  Located_In       0.50      1.00      0.67         1\n",
      "        None       0.00      0.00      0.00         7\n",
      " OrgBased_In       0.56      0.83      0.67         6\n",
      "    Work_For       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.45      0.72      0.55        20\n",
      "weighted avg       0.36      0.55      0.43        20\n",
      "\n",
      "['Work_For', 'Live_In', 'Kill', 'Located_In', 'None', 'OrgBased_In']\n",
      "[[2 0 0 0 1 0]\n",
      " [0 2 0 0 1 1]\n",
      " [0 0 1 0 1 0]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 3 5]]\n",
      "The Classification Report of  Base Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-Loc       0.88      0.88      0.88        16\n",
      "       B-Org       0.73      0.89      0.80         9\n",
      "     B-Other       1.00      0.75      0.86         4\n",
      "      B-Peop       0.89      0.57      0.70        14\n",
      "       I-Loc       1.00      0.50      0.67         6\n",
      "       I-Org       0.61      0.92      0.73        12\n",
      "     I-Other       1.00      0.80      0.89         5\n",
      "      I-Peop       0.92      1.00      0.96        11\n",
      "           O       0.97      0.98      0.98       232\n",
      "\n",
      "    accuracy                           0.94       309\n",
      "   macro avg       0.89      0.81      0.83       309\n",
      "weighted avg       0.94      0.94      0.93       309\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Loc       0.89      0.81      0.85        21\n",
      "           O       0.97      0.97      0.97       232\n",
      "         Org       0.69      0.83      0.75        24\n",
      "        Peop       0.95      0.80      0.87        25\n",
      "\n",
      "    accuracy                           0.94       302\n",
      "   macro avg       0.88      0.85      0.86       302\n",
      "weighted avg       0.94      0.94      0.94       302\n",
      "\n",
      "['Peop', 'Org', 'O', 'Loc']\n",
      "[[ 20   0   1   0]\n",
      " [  1  20   4   4]\n",
      " [  3   4 226   0]\n",
      " [  1   0   1  17]]\n"
     ]
    }
   ],
   "source": [
    "def getInferenceResults(filename):\n",
    "    with open (filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        results_dict = dict()\n",
    "        for line in lines:\n",
    "\n",
    "            probability = float(line.split(' ')[1])\n",
    "            start = 0\n",
    "            while(line[start] != '('):\n",
    "                start = start + 1\n",
    "            start = start + 1\n",
    "            end = start\n",
    "            while(line[end]!=')'):\n",
    "                end = end + 1\n",
    "\n",
    "            content = line[start:end].split(',')\n",
    "#             print(content,probability)\n",
    "            if line[0] == 'E':\n",
    "                if content[0]+'-'+content[1] in results_dict and results_dict[content[0]+'-'+content[1]][1] < probability:\n",
    "                    results_dict[content[0]+'-'+content[1]] = (content[2], probability)\n",
    "                elif content[0]+'-'+content[1] not in results_dict:\n",
    "                    results_dict[content[0]+'-'+content[1]] = (content[2], probability)\n",
    "\n",
    "            else:\n",
    "                if content[0]+'-'+content[1]+'-'+content[2] in results_dict and results_dict[content[0]+'-'+content[1]+'-'+content[2]][1] < probability:\n",
    "                    results_dict[content[0]+'-'+content[1]+'-'+content[2]] = (content[3],probability)\n",
    "                elif content[0]+'-'+content[1]+'-'+content[2] not in results_dict:\n",
    "                    results_dict[content[0]+'-'+content[1]+'-'+content[2]] = (content[3],probability)\n",
    "#         print(results_dict)\n",
    "        return results_dict\n",
    "\n",
    "def getClassifierReport(file,label,labels):\n",
    "    data = pd.read_csv(file) \n",
    "\n",
    "    predicted_tags = data['Predicted']\n",
    "    gold_truths = data['Gold Truth']\n",
    "    print('The Classification Report of ',label)\n",
    "    print(classification_report(predicted_tags,gold_truths))\n",
    "\n",
    "def getAlchemyReport(file,label,mln_results,labels):\n",
    "    THRESHOLD = 0.1\n",
    "    data = pd.read_csv(file)\n",
    "    actual_tags = []\n",
    "    predicted_tags = []\n",
    "    \n",
    "#     print(mln_results)\n",
    "    if label == 'Base Classifier':\n",
    "        THRESHOLD = 0.1\n",
    "        for sentenceID,tokenID, gold_truth in zip(data['SentenceID'],data['tokenID'],data['Gold Truth']):\n",
    "            key = str(sentenceID) + '-'+str(tokenID)\n",
    "            if 'Other' not in gold_truth:\n",
    "                if len(gold_truth) > 2:\n",
    "                    actual_tags.append(gold_truth[2:])\n",
    "                else:\n",
    "                    actual_tags.append(gold_truth)\n",
    "                if key in mln_results.keys() and mln_results[key][1] > THRESHOLD:\n",
    "                    predicted_tags.append(mln_results[key][0])\n",
    "                else:\n",
    "                    predicted_tags.append('O')\n",
    "\n",
    "        \n",
    "    else:\n",
    "        THRESHOLD = 0.005\n",
    "        for sentenceID,token1,token2,gold_truth in zip(data['SentenceID'],data['token1'],data['token2'],data['Gold Truth']):\n",
    "            key = str(sentenceID) + '-'+str(token1)+'-'+str(token2)\n",
    "            \n",
    "#             if gold_truth != 'None':\n",
    "            actual_tags.append(gold_truth)\n",
    "            if key in mln_results.keys() and mln_results[key][1] > THRESHOLD:\n",
    "                predicted_tags.append(mln_results[key][0])\n",
    "            else:\n",
    "                    predicted_tags.append('None')\n",
    "        \n",
    "#     print(\"Predicted Tag----------Actual Tag\")\n",
    "#     for i in range(len(actual_tags)):\n",
    "#         print(predicted_tags[i]+'------------'+actual_tags[i])\n",
    "    \n",
    "#     print('The Classification Report(Alchemy) of ',label)\n",
    "    \n",
    "\n",
    "    print(classification_report(predicted_tags,actual_tags))\n",
    "    print(labels)\n",
    "    print(confusion_matrix(actual_tags,predicted_tags,labels=labels))\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    mln_results = getInferenceResults('inference_results_10.results')\n",
    "    \n",
    "#     print(mln_results['1-21-5'][1]*100)\n",
    "\n",
    "#     print(mln_results)\n",
    "\n",
    "    entities = ['Peop','Org','O','Loc']\n",
    "    relations = ['Work_For','Live_In','Kill','Located_In','None','OrgBased_In']\n",
    "    getClassifierReport(\"relation_classifier.csv\",'Relation Classifier',relations)\n",
    "    getAlchemyReport('relation_classifier_10.csv','Relation Classifier',mln_results,relations)\n",
    "    \n",
    "    getClassifierReport(\"base_classifier_10.csv\",'Base Classifier',entities)\n",
    "    getAlchemyReport('base_classifier_10.csv','Base Classifier',mln_results,entities)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Report of  Base Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-Loc       0.88      0.88      0.88        16\n",
      "       B-Org       0.73      0.89      0.80         9\n",
      "     B-Other       1.00      0.75      0.86         4\n",
      "      B-Peop       0.89      0.57      0.70        14\n",
      "       I-Loc       1.00      0.50      0.67         6\n",
      "       I-Org       0.61      0.92      0.73        12\n",
      "     I-Other       1.00      0.80      0.89         5\n",
      "      I-Peop       0.92      1.00      0.96        11\n",
      "           O       0.97      0.98      0.98       232\n",
      "\n",
      "    accuracy                           0.94       309\n",
      "   macro avg       0.89      0.81      0.83       309\n",
      "weighted avg       0.94      0.94      0.93       309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    getReport(\"base_classifier_10.csv\",'Base Classifier')\n",
    "#     getReport(\"relation_classifier.csv\",'Relation Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
